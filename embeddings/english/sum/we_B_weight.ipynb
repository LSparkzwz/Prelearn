{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "we_B_weight.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNa2mg45Be3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create doc embeddings with fasttext by averaging word embeddings\n",
        "weight_A = 1\n",
        "weight_B = 20\n",
        "\n",
        "#create train dataset\n",
        "\n",
        "ft_train = {k: [] for k in range(600)}\n",
        "ft_train['prerequisite'] = []\n",
        "for index, row in train.iterrows():\n",
        "    A = doc_dict[row[0]]\n",
        "    B = doc_dict[row[1]]\n",
        "    doc_embedding_A = np.zeros(300)\n",
        "    doc_embedding_B = np.zeros(300)\n",
        "\n",
        "    for word in A:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_A = doc_embedding_A + word_embedding\n",
        "    for word in B:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_B = doc_embedding_B + word_embedding  \n",
        "\n",
        "    data = np.concatenate([weight_A * doc_embedding_A, weight_B * doc_embedding_B]) \n",
        "    for i,val in enumerate(data):\n",
        "      ft_train[i].append(val)\n",
        "    ft_train['prerequisite'].append(row[2])\n",
        "\n",
        "#create validation dataset\n",
        "\n",
        "ft_validation = {k: [] for k in range(600)}\n",
        "ft_validation['prerequisite'] = []\n",
        "for index, row in validation.iterrows():\n",
        "    A = doc_dict[row[0]]\n",
        "    B = doc_dict[row[1]]\n",
        "    doc_embedding_A = np.zeros(300)\n",
        "    doc_embedding_B = np.zeros(300)\n",
        "\n",
        "    for word in A:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_A = doc_embedding_A + word_embedding\n",
        "    for word in B:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_B = doc_embedding_B + word_embedding  \n",
        "\n",
        "    data = np.concatenate([weight_A * doc_embedding_A, weight_B * doc_embedding_B]) \n",
        "    for i,val in enumerate(data):\n",
        "      ft_validation[i].append(val)\n",
        "    ft_validation['prerequisite'].append(row[2])\n",
        "\n",
        "ft_df_train = pd.DataFrame(data = ft_train)\n",
        "ft_df_validation = pd.DataFrame(data = ft_validation)\n",
        "\n",
        "y_train = ft_df_train.iloc[:,600]\n",
        "X_train = ft_df_train.iloc[:,:600]\n",
        "\n",
        "X_test = ft_df_validation.iloc[:,:600]\n",
        "y_test = ft_df_validation.iloc[:,600]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}