{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "second_approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vurXuTaNCHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "!pip install wikipedia\n",
        "!pip install fasttext\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "import wikipedia\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from pprint import pprint as print\n",
        "from gensim.models.fasttext import FastText as fasttext\n",
        "from gensim.test.utils import datapath\n",
        "from google.colab import drive\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import fasttext.util\n",
        "import sklearn as sk\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VnlWxIfHb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initial setup\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "fasttext.util.download_model('it', if_exists='ignore') \n",
        "ft = fasttext.load_model('cc.it.300.bin')\n",
        "\n",
        "wikipedia.set_lang(\"it\")\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03BN0_1dfMty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset init\n",
        "\n",
        "#dataset consisting of pairs of concepts and a subject (physics, geomery, data_mining or precalcus) tag\n",
        "#and consisting of pairs of target and prerequisite concepts (A, B) labelled as follows:\n",
        "#1 if B is a prerequisite of A;\n",
        "#0 in all other cases.\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/m_dataset.csv')\n",
        "\n",
        "#The Wikipedia page of each concept found in the previous file.\n",
        "#Each Wikipedia page is introduced by a `<doc>` element (with *id* and *url*) \n",
        "#containing the title and the text of the corresponding page.\n",
        "tree = ET.parse('/content/drive/My Drive/dataset.xml')\n",
        "pages = tree.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ghW2hZ8d1ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dictionary of doc embeddings\n",
        "#doc embedding is the averaged word embeddings\n",
        "\n",
        "punct = string.punctuation + '«``»' + \"''\"\n",
        "it_stop_words = nltk.corpus.stopwords.words('italian')\n",
        "stemmer = nltk.stem.snowball.ItalianStemmer(True)\n",
        "\n",
        "doc_dict = {}\n",
        "\n",
        "for content in pages.iter('doc'):\n",
        "  #document to lowercase, replaced apostrophe with space since the tokenizer isn't able to split words like \"l'addizione\"\n",
        "  document = (content.find('title').text  + content.find('text').text).replace(\"'\",\" \")\n",
        "  #tokenized\n",
        "  tokenized = nltk.tokenize.word_tokenize(document, \"italian\")\n",
        "  #no punctuation and lowercase\n",
        "  no_punct = [x.lower() for x in tokenized if x not in punct]\n",
        "  #remove stop words\n",
        "  no_stop_words = [x for x in no_punct if x not in it_stop_words]\n",
        "  #doc embedding\n",
        "  doc_embedding = np.zeros(300)\n",
        "  for word in no_stop_words:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding = doc_embedding + word_embedding\n",
        "  doc_embedding = doc_embedding / len(no_stop_words)    \n",
        "\n",
        "  \n",
        "  #add tokenized document\n",
        "  doc_dict[content.find('title').text] = doc_embedding"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf10-SEqhWUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create doc embeddings with fasttext by averaging word embeddings\n",
        "\n",
        "#create train dataset\n",
        "\n",
        "ft_train = {k: [] for k in range(600)}\n",
        "ft_train['prerequisite'] = []\n",
        "for index, row in train.iterrows():\n",
        "    A = doc_dict[row[0]]\n",
        "    B = doc_dict[row[1]]\n",
        "    doc_embedding_A = np.zeros(300)\n",
        "    doc_embedding_B = np.zeros(300)\n",
        "\n",
        "    for word in A:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_A = doc_embedding_A + word_embedding\n",
        "    for word in B:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_B = doc_embedding_B + word_embedding  \n",
        "    \n",
        "    #averaged doc_embeddings\n",
        "    doc_embedding_A = doc_embedding_A / len(A)\n",
        "    doc_embedding_B = doc_embedding_B / len(B)\n",
        "\n",
        "    data = np.concatenate([doc_embedding_A, doc_embedding_B]) \n",
        "    for i,val in enumerate(data):\n",
        "      ft_train[i].append(val)\n",
        "    ft_train['prerequisite'].append(row[2])\n",
        "\n",
        "#create validation dataset\n",
        "\n",
        "ft_validation = {k: [] for k in range(600)}\n",
        "ft_validation['prerequisite'] = []\n",
        "for index, row in validation.iterrows():\n",
        "    A = doc_dict[row[0]]\n",
        "    B = doc_dict[row[1]]\n",
        "    doc_embedding_A = np.zeros(300)\n",
        "    doc_embedding_B = np.zeros(300)\n",
        "\n",
        "    for word in A:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_A = doc_embedding_A + word_embedding\n",
        "    for word in B:\n",
        "      word_embedding = np.array(ft.get_word_vector(word))\n",
        "      doc_embedding_B = doc_embedding_B + word_embedding  \n",
        "    \n",
        "    #averaged doc_embeddings\n",
        "    doc_embedding_A = doc_embedding_A / len(A)\n",
        "    doc_embedding_B = doc_embedding_B / len(B)\n",
        "\n",
        "    data = np.concatenate([doc_embedding_A, doc_embedding_B]) \n",
        "    for i,val in enumerate(data):\n",
        "      ft_validation[i].append(val)\n",
        "    ft_validation['prerequisite'].append(row[2])\n",
        "\n",
        "ft_df_train = pd.DataFrame(data = ft_train)\n",
        "ft_df_validation = pd.DataFrame(data = ft_validation)\n",
        "\n",
        "y_train = ft_df_train.iloc[:,600]\n",
        "X_train = ft_df_train.iloc[:,:600]\n",
        "\n",
        "X_test = ft_df_validation.iloc[:,:600]\n",
        "y_test = ft_df_validation.iloc[:,600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjs8FVdpl2NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datasets for each subject\n",
        "\n",
        "subject_df_dict = {}\n",
        "subject_df_dict[\"physics\"] = {k: [] for k in range(600)}\n",
        "subject_df_dict[\"physics\"]['prerequisite'] = []\n",
        "subject_df_dict[\"geometry\"] = {k: [] for k in range(600)}\n",
        "subject_df_dict[\"geometry\"]['prerequisite'] = []\n",
        "subject_df_dict[\"data-mining\"] = {k: [] for k in range(600)}\n",
        "subject_df_dict[\"data-mining\"]['prerequisite'] = []\n",
        "subject_df_dict[\"precalculus\"] = {k: [] for k in range(600)}\n",
        "subject_df_dict[\"precalculus\"]['prerequisite'] = []\n",
        "\n",
        "df_embeddings = {k: [] for k in range(600)}\n",
        "df_embeddings['prerequisite'] = []\n",
        "df_embeddings['subject'] = []\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "  data = np.concatenate([doc_dict[row[0]], doc_dict[row[1]]])\n",
        "  is_prerequisite = row[2]\n",
        "  subject = row[3]\n",
        "\n",
        "  for i,val in enumerate(data):\n",
        "    df_embeddings[i].append(val)\n",
        "    subject_df_dict[subject][i].append(val)\n",
        "\n",
        "  df_embeddings['prerequisite'].append(is_prerequisite)\n",
        "  subject_df_dict[subject]['prerequisite'].append(is_prerequisite)\n",
        "  df_embeddings['subject'].append(subject)\n",
        "\n",
        "#split the various datasets into train and validation\n",
        "\n",
        "df = pd.DataFrame(data = df_embeddings)\n",
        "df_train = df.sample(frac=0.8,random_state=200) \n",
        "df_validation = df.drop(df_train.index)\n",
        "\n",
        "physics_df = pd.DataFrame(data = subject_df_dict[\"physics\"])\n",
        "physics_train = physics_df.sample(frac=0.8,random_state=200) \n",
        "physics_validation = physics_df.drop(physics_train.index)\n",
        "\n",
        "geometry_df = pd.DataFrame(data = subject_df_dict[\"geometry\"])\n",
        "geometry_train = geometry_df.sample(frac=0.8,random_state=200) \n",
        "geometry_validation = geometry_df.drop(geometry_train.index)\n",
        "\n",
        "data_mining_df = pd.DataFrame(data = subject_df_dict[\"data-mining\"])\n",
        "data_mining_train = data_mining_df.sample(frac=0.8,random_state=200) \n",
        "data_mining_validation = data_mining_df.drop(data_mining_train.index)\n",
        "\n",
        "precalculus_df = pd.DataFrame(data = subject_df_dict[\"precalculus\"])\n",
        "precalculus_train = precalculus_df.sample(frac=0.8,random_state=200) \n",
        "precalculus_validation = precalculus_df.drop(precalculus_train.index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_n6PfbwmTft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#subject classificator\n",
        "\n",
        "y_subject_train = df_train.iloc[:,601]\n",
        "X_subject_train = df_train.iloc[:,:600]\n",
        "\n",
        "y_subject_test = df_validation.iloc[:,601]\n",
        "X_subject_test = df_validation.iloc[:,:600]\n",
        "\n",
        "#rbf SVM\n",
        "\n",
        "#train\n",
        "SVM = svm.SVC(max_iter=100000,C=500, gamma=10)\n",
        "SVM.fit(X_subject_train, y_subject_train)\n",
        "\n",
        "#validate\n",
        "y_subject_pred = SVM.predict(X_subject_test)\n",
        "\n",
        "print('Accuracy score: {:3f}'.format(accuracy_score(y_subject_test, y_subject_pred)))\n",
        "print('Precision score: {:3f}'.format(precision_score(y_subject_test, y_subject_pred,average='macro',labels=['physics','geometry','data-mining','precalculus'])))\n",
        "print('Recall score: {:3f}'.format(recall_score(y_subject_test, y_subject_pred,average='macro',labels=['physics','geometry','data-mining','precalculus'])))\n",
        "print('F1 score: {:3f}'.format(f1_score(y_subject_test, y_subject_pred,average='macro',labels=['physics','geometry','data-mining','precalculus'])))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9OW3_TQtBkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#geometry classificator\n",
        "\n",
        "y_geometry_train = geometry_train.iloc[:,600]\n",
        "X_geometry_train = geometry_train.iloc[:,:600]\n",
        "\n",
        "y_geometry_test = geometry_validation.iloc[:,600]\n",
        "X_geometry_test = geometry_validation.iloc[:,:600]\n",
        "\n",
        "#rbf SVM\n",
        "\n",
        "#train\n",
        "SVM = svm.SVC(max_iter=100000,C=500, gamma=10)\n",
        "SVM.fit(X_geometry_train, y_geometry_train)\n",
        "\n",
        "#validate\n",
        "y_geometry_pred = SVM.predict(X_geometry_test)\n",
        "\n",
        "print('Accuracy score: {:3f}'.format(accuracy_score(y_geometry_test, y_geometry_pred)))\n",
        "print('Precision score: {:3f}'.format(precision_score(y_geometry_test, y_geometry_pred)))\n",
        "print('Recall score: {:3f}'.format(recall_score(y_geometry_test, y_geometry_pred)))\n",
        "print('F1 score: {:3f}'.format(f1_score(y_geometry_test, y_geometry_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azhR1NHtuq6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#physics classificator\n",
        "\n",
        "y_physics_train = physics_train.iloc[:,600]\n",
        "X_physics_train = physics_train.iloc[:,:600]\n",
        "\n",
        "y_physics_test = physics_validation.iloc[:,600]\n",
        "X_physics_test = physics_validation.iloc[:,:600]\n",
        "\n",
        "#rbf SVM\n",
        "\n",
        "#train\n",
        "SVM = svm.SVC(max_iter=100000,C=500, gamma=10)\n",
        "SVM.fit(X_physics_train, y_physics_train)\n",
        "\n",
        "#validate\n",
        "y_physics_pred = SVM.predict(X_physics_test)\n",
        "\n",
        "print('Accuracy score: {:3f}'.format(accuracy_score(y_physics_test, y_physics_pred)))\n",
        "print('Precision score: {:3f}'.format(precision_score(y_physics_test, y_physics_pred)))\n",
        "print('Recall score: {:3f}'.format(recall_score(y_physics_test, y_physics_pred)))\n",
        "print('F1 score: {:3f}'.format(f1_score(y_physics_test, y_physics_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yS9hYCUurOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_mining classificator\n",
        "\n",
        "y_data_mining_train = data_mining_train.iloc[:,600]\n",
        "X_data_mining_train = data_mining_train.iloc[:,:600]\n",
        "\n",
        "y_data_mining_test = data_mining_validation.iloc[:,600]\n",
        "X_data_mining_test = data_mining_validation.iloc[:,:600]\n",
        "\n",
        "#rbf SVM\n",
        "\n",
        "#train\n",
        "RF = RandomForestClassifier(max_features = None)\n",
        "RF.fit(X_data_mining_train, y_data_mining_train)\n",
        "\n",
        "#validate\n",
        "y_data_mining_pred = RF.predict(X_data_mining_test)\n",
        "\n",
        "print('Accuracy score: {:3f}'.format(accuracy_score(y_data_mining_test, y_data_mining_pred)))\n",
        "print('Precision score: {:3f}'.format(precision_score(y_data_mining_test, y_data_mining_pred)))\n",
        "print('Recall score: {:3f}'.format(recall_score(y_data_mining_test, y_data_mining_pred)))\n",
        "print('F1 score: {:3f}'.format(f1_score(y_data_mining_test, y_data_mining_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8CrdsTurU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#precaulculus classificator\n",
        "\n",
        "y_precalculus_train = precalculus_train.iloc[:,600]\n",
        "X_precalculus_train = precalculus_train.iloc[:,:600]\n",
        "\n",
        "y_precalculus_test = precalculus_validation.iloc[:,600]\n",
        "X_precalculus_test = precalculus_validation.iloc[:,:600]\n",
        "\n",
        "#rbf SVM\n",
        "\n",
        "#train\n",
        "SVM = svm.SVC(max_iter=100000,C=500, gamma=10)\n",
        "SVM.fit(X_precalculus_train, y_precalculus_train)\n",
        "\n",
        "#validate\n",
        "y_precalculus_pred = SVM.predict(X_precalculus_test)\n",
        "\n",
        "print('Accuracy score: {:3f}'.format(accuracy_score(y_precalculus_test, y_precalculus_pred)))\n",
        "print('Precision score: {:3f}'.format(precision_score(y_precalculus_test, y_precalculus_pred)))\n",
        "print('Recall score: {:3f}'.format(recall_score(y_precalculus_test, y_precalculus_pred)))\n",
        "print('F1 score: {:3f}'.format(f1_score(y_precalculus_test, y_precalculus_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}